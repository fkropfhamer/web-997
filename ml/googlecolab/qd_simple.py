# -*- coding: utf-8 -*-
"""ml003_qd_simple.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15-ACPuYz-JbtE0eG0UMcqY-05QyKCVw2
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

import tensorflow as tf
import tensorflow.keras as keras
import numpy as np

physical_devices = tf.config.list_physical_devices('GPU') 
if len(physical_devices) <= 0:
  raise ValueError("No GPU detected!")
print("Num GPUs:", len(physical_devices))

classes = ["ant", "fish", "tree", "bee", "sun", "star", "clock", "flower", "car", "cactus"]
print(len(classes))

import urllib.request
def download(classes):
  
  base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'
  for c in classes:
    cls_url = c.replace('_', '%20')
    path = base+cls_url+'.npy'
    print(path)
    urllib.request.urlretrieve(path, c+'.npy')

download(classes)

import os
import glob
import numpy as np

all_files = glob.glob('*.npy')

features = np.empty([0, 784])
labels = np.empty([0])
class_names = []

print(all_files)
data_per_class = 50000

for i, file in enumerate(all_files):
  data = np.load(file)
  data = data[0: data_per_class, :]
  labels_array = np.full(data.shape[0], i)

  features = np.concatenate((features, data), axis=0)
  labels = np.append(labels, labels_array)

  class_name, ext = os.path.splitext(os.path.basename(file))
  class_names.append(class_name)

data = None
labels_array = None

print(class_names)

from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split

features, labels = shuffle(features, labels)

train_features, test_features, train_labels, test_labels = train_test_split(features, labels, random_state=0, test_size=0.1)

train_features = train_features.reshape(train_features.shape[0], 28, 28, 1).astype('float32')
test_features = test_features.reshape(test_features.shape[0], 28, 28, 1).astype('float32')

train_features = train_features / 255.0
test_features = test_features / 255.0


train_labels = keras.utils.to_categorical(train_labels, 10)
test_labels = keras.utils.to_categorical(test_labels, 10)

print(train_features.shape)

model = keras.models.Sequential([
                                  keras.layers.Conv2D(32, (5,5), input_shape=(28, 28, 1), activation='relu'),
                                  keras.layers.Conv2D(32, (5, 5), activation='relu'),
                                  keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),
                                  keras.layers.Dropout(0.25),
                                  
                                  keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),
                                  keras.layers.Conv2D(64, (5, 5), activation='relu'),
                                  keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'),

                                  keras.layers.Flatten(),
                                  keras.layers.Dense(512, activation='relu'),
                                  keras.layers.Dropout(0.5),
                                  keras.layers.Dense(128, activation='relu'),
                                  keras.layers.Dropout(0.5),
                                  keras.layers.Dense(10, activation='softmax'),

])

model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])

model.fit(train_features, train_labels, validation_data=(test_features, test_labels), epochs=50, batch_size=64)

loss, accuracy = model.evaluate(test_features, test_labels)
print("loss: {}, accuracy: {}".format(loss, accuracy))

model.save("model.h5")

with open("classes.txt", mode="w") as f:
  for class_name in class_names:
    f.write(class_name)
    f.write("\n")